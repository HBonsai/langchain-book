{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzrWQTLn70Ra"
      },
      "source": [
        "# ChatGPTをAPIから利用するために"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKSpjd8v8A9H"
      },
      "source": [
        "## 3-3 入出力の長さの制限や課金に影響する「トークン」"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6fSq7bc8DES"
      },
      "source": [
        "### Tokenizerとtiktokenの紹介"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MPred-0se6z"
      },
      "outputs": [],
      "source": [
        "!pip install tiktoken==0.5.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WWdpn2pw8NGp"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "\n",
        "text = \"It’s easy to make something cool with LLMs, but very hard to make something production-ready with them.\"\n",
        "\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "tokens = encoding.encode(text)\n",
        "print(len(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwIhYtWcshOY"
      },
      "outputs": [],
      "source": [
        "text = \"LLMを使ってクールなものを作るのは簡単だが、プロダクションで使えるものを作るのは非常に難しい。\"\n",
        "\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "tokens = encoding.encode(text)\n",
        "print(len(tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P56iAwzT8Xmq"
      },
      "source": [
        "## 3-4 Chat Completions APIにふれる環境準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIZY8RE38cUC"
      },
      "source": [
        "### Google Colabのノートブック作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4TeCLj3Qe5r"
      },
      "outputs": [],
      "source": [
        "print(\"Hello World\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjYCIb2Q8fbe"
      },
      "source": [
        "### OpenAIのAPIキーの準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y4oSu5DqWgpG"
      },
      "outputs": [],
      "source": [
        "# 2023年11月、Google ColabにAPIキーなどの機密情報を安全に管理する機能が追加されました。\n",
        "# 画面左側の鍵のマークから「シークレット」を開いて、「OPENAI_API_KEY」という名前でOpenAIのAPIキーを保存してから、このセルを実行してください。\n",
        "#\n",
        "# 参考: https://twitter.com/GoogleColab/status/1719798406195867814\n",
        "\n",
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0l8ptIe8iH5"
      },
      "source": [
        "## 3-5 Chat Completions APIをさわってみる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p9pLImp8kQ9"
      },
      "source": [
        "### OpenAIのライブラリ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_R8jT7MNRC9t"
      },
      "outputs": [],
      "source": [
        "# 2023年11月、openaiパッケージのバージョン1.0がリリースされました。\n",
        "# その際、以前のバージョンとは使用方法が大きく変更されました。\n",
        "# 以後のコードはopenaiのバージョン1.10.0で動作するようにしてあります。\n",
        "\n",
        "!pip install openai==1.10.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTD-Xe9G8r6w"
      },
      "source": [
        "### Chat Completions APIの呼び出し"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHJUSC61Wg_y"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Hello! I'm John.\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2THywRt8t0F"
      },
      "source": [
        "### 会話履歴を踏まえた応答を得る"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yk5Cc6rtWtub"
      },
      "outputs": [],
      "source": [
        "client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Hello! I'm John.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Hello John! How can I assist you today?\"},\n",
        "        {\"role\": \"user\", \"content\": \"Do you know my name?\"}\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKRqvj0u8xWL"
      },
      "source": [
        "### ストリーミングで応答を得る"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7J2Gq9PYPBA"
      },
      "outputs": [],
      "source": [
        "stream = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Hello! I'm John.\"}\n",
        "  ],\n",
        "  stream=True\n",
        ")\n",
        "\n",
        "for chunk in stream:\n",
        "  content = chunk.choices[0].delta.content\n",
        "  if content is not None:\n",
        "    print(content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqKaUhJ08zQ1"
      },
      "source": [
        "### （コラム）Completions API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fD6Z-BZsCF3P"
      },
      "outputs": [],
      "source": [
        "# Completions APIで使用可能だったモデル「text-davinci-003」は、2024年1月に廃止されました。\n",
        "# 代替としてCompletions APIでは「gpt-3.5-turbo-instruct」を使うことになったため、ここでは「gpt-3.5-turbo-instruct」を使用しています。\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.completions.create(\n",
        "  model=\"gpt-3.5-turbo-instruct\",\n",
        "  prompt=\"Hello! I'm John.\"\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKiq30SODvUP"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Human: Hello! I'm John.\n",
        "AI: Nice to meet you, John!\n",
        "Human: Do you know my name?\n",
        "AI: \"\"\"\n",
        "\n",
        "response = client.completions.create(\n",
        "  model=\"gpt-3.5-turbo-instruct\",\n",
        "  prompt=prompt\n",
        ")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrlT300r83MS"
      },
      "source": [
        "## 3-6 Function calling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwG5cpzg85Vn"
      },
      "source": [
        "### Function callingのサンプルコード\n",
        "\n",
        "~[OpenAI の公式ドキュメント](https://platform.openai.com/docs/guides/gpt/function-calling) をもとに一部改変したコードです。~\n",
        "\n",
        "大幅アップデートされたOpenAIの公式ドキュメントの、次のページのコードをもとに一部改変したコードです。\n",
        "\n",
        "https://platform.openai.com/docs/guides/function-calling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K97Pbcw3bly8"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def get_current_weather(location, unit=\"celsius\"):\n",
        "    weather_info = {\n",
        "        \"location\": location,\n",
        "        \"temperature\": \"25\",\n",
        "        \"unit\": \"celsius\",\n",
        "        \"forecast\": [\"sunny\", \"windy\"],\n",
        "    }\n",
        "    return json.dumps(weather_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgIGMKtBgeGj"
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"get_current_weather\",\n",
        "            \"description\": \"Get the current weather in a given location\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"location\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The city and state, e.g. Tokyo\",\n",
        "                    },\n",
        "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
        "                },\n",
        "                \"required\": [\"location\"],\n",
        "            },\n",
        "        }\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO-VYo7tghih"
      },
      "outputs": [],
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Tokyo?\"}]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        "    # Function callingでは、functionsというパラメータは非推奨となり、代わりに「tools」というパラメータを使用するのが推奨になりました。\n",
        "    tools=tools\n",
        ")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7LcVydmhlp0"
      },
      "outputs": [],
      "source": [
        "response_message = response.choices[0].message\n",
        "messages.append(response_message)\n",
        "\n",
        "tool_calls = response_message.tool_calls\n",
        "\n",
        "available_functions = {\n",
        "    \"get_current_weather\": get_current_weather,\n",
        "}\n",
        "\n",
        "# tool_callsには複数のツールの呼び出しが含まれる可能性があるため、ループで順に処理します。\n",
        "for tool_call in tool_calls:\n",
        "    function_name = tool_call.function.name\n",
        "    fuction_to_call = available_functions[function_name]\n",
        "    function_args = json.loads(tool_call.function.arguments)\n",
        "\n",
        "    function_response = fuction_to_call(\n",
        "        location=function_args.get(\"location\"),\n",
        "        unit=function_args.get(\"unit\"),\n",
        "    )\n",
        "\n",
        "    print(function_response)\n",
        "\n",
        "    messages.append(\n",
        "        {\n",
        "            \"tool_call_id\": tool_call.id,\n",
        "            \"role\": \"tool\",\n",
        "            \"name\": function_name,\n",
        "            \"content\": function_response,\n",
        "        }\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9QBhpRtgtSW"
      },
      "outputs": [],
      "source": [
        "second_response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=messages,\n",
        ")\n",
        "\n",
        "print(second_response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
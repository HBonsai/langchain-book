{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 4. LangChain解説"
      ],
      "metadata": {
        "id": "tUj2y-stek1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your-openai-api-key\""
      ],
      "metadata": {
        "id": "y4oSu5DqWgpG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-1 LangChainの概要"
      ],
      "metadata": {
        "id": "d3cSlNQV9ZBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet langchain openai"
      ],
      "metadata": {
        "id": "WqgjYwQUemjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-2 Language models"
      ],
      "metadata": {
        "id": "gMModXMNetUP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LLMs"
      ],
      "metadata": {
        "id": "u3elDRjh9jVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
        "\n",
        "result = llm(\"自己紹介してください。\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "WY3sdyngepk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chat models"
      ],
      "metadata": {
        "id": "nvqkiiI-9mI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
        "    HumanMessage(content=\"こんにちは！私はジョンと言います！\"),\n",
        "    AIMessage(content=\"こんにちは、ジョンさん！どのようにお手伝いできますか？\"),\n",
        "    HumanMessage(content= \"私の名前が分かりますか？\")\n",
        "]\n",
        "\n",
        "result = chat(messages)\n",
        "print(result.content)"
      ],
      "metadata": {
        "id": "fLI_K6YIewJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Callbackを使ったストリーミング"
      ],
      "metadata": {
        "id": "KLRYe3Ec9qAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "chat = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    temperature=0,\n",
        "    streaming=True,\n",
        "    callbacks=[StreamingStdOutCallbackHandler()],\n",
        ")\n",
        "\n",
        "messages = [HumanMessage(content=\"自己紹介してください\")]\n",
        "result = chat(messages)"
      ],
      "metadata": {
        "id": "WLxGXw7zgXlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-3 Prompts"
      ],
      "metadata": {
        "id": "eRH_6qBQnEjZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt templates"
      ],
      "metadata": {
        "id": "eJvnkWfA9tIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "以下の料理のレシピを教えてください。\n",
        "\n",
        "料理名: {dish}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "   input_variables=[\"dish\"],\n",
        "   template=template,\n",
        ")\n",
        "\n",
        "result = prompt.format(dish=\"カレー\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "XLfdULPOjUDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ChatPromptTemplate"
      ],
      "metadata": {
        "id": "BIYyxXfj9viN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    PromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import HumanMessage, SystemMessage\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    SystemMessagePromptTemplate.from_template(\"あなたは{country}料理のプロフェッショナルです。\"),\n",
        "    HumanMessagePromptTemplate.from_template(\"以下の料理のレシピを教えてください。\\n\\n料理名: {dish}\")\n",
        "])\n",
        "\n",
        "messages = chat_prompt.format_prompt(country=\"フランス\", dish=\"肉じゃが\").to_messages()\n",
        "\n",
        "print(messages)"
      ],
      "metadata": {
        "id": "cUvu-76mnWBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "result = chat(messages)\n",
        "print(result.content)"
      ],
      "metadata": {
        "id": "5-WsdEpEsNta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-4 Output Parsers\n"
      ],
      "metadata": {
        "id": "B9SAbwnNwFQq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PydanticOutputParser"
      ],
      "metadata": {
        "id": "3gUPEasNNBlP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Recipe(BaseModel):\n",
        "   ingredients: list[str] = Field(description=\"ingredients of the dish\")\n",
        "   steps: list[str] = Field(description=\"steps to make the dish\")"
      ],
      "metadata": {
        "id": "FEkmkZixwEdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.output_parsers import PydanticOutputParser\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object=Recipe)"
      ],
      "metadata": {
        "id": "aosaD-s-wExZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from logging import Formatter\n",
        "format_instructions = parser.get_format_instructions()\n",
        "\n",
        "print(format_instructions)"
      ],
      "metadata": {
        "id": "blhjs33M-AHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"\"\"料理のレシピを教えてください。\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "料理名: {dish}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "   template=template,\n",
        "   input_variables=[\"dish\"],\n",
        "   partial_variables={\"format_instructions\": format_instructions}\n",
        ")"
      ],
      "metadata": {
        "id": "21EfCn8b-AFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = prompt.format(dish=\"カレー\")\n",
        "\n",
        "print(input)"
      ],
      "metadata": {
        "id": "z5Y0KvYk-ADU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "messages = [HumanMessage(content=input)]\n",
        "output = chat(messages)\n",
        "\n",
        "print(output.content)"
      ],
      "metadata": {
        "id": "5gQjKsGy9__B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recipe = parser.parse(output.content)\n",
        "print(recipe)"
      ],
      "metadata": {
        "id": "ZY4cBqNZ9_1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-4 Chains"
      ],
      "metadata": {
        "id": "LUVnoApz-v9O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LLMChain―PromptTemplate・Language model・OutputParserをつなぐ"
      ],
      "metadata": {
        "id": "YU0czqQn-xgL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Recipe(BaseModel):\n",
        "   ingredients: list[str] = Field(description=\"ingredients of the dish\")\n",
        "   steps: list[str] = Field(description=\"steps to make the dish\")\n",
        "\n",
        "output_parser = PydanticOutputParser(pydantic_object=Recipe)\n",
        "\n",
        "template = \"\"\"料理のレシピを教えてください。\n",
        "\n",
        "{format_instructions}\n",
        "\n",
        "料理名: {dish}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "   template=template,\n",
        "   input_variables=[\"dish\"],\n",
        "   partial_variables={\"format_instructions\": output_parser.get_format_instructions()}\n",
        ")\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
      ],
      "metadata": {
        "id": "bpPIlgjpyroZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LLMChain\n",
        "\n",
        "chain = LLMChain(prompt=prompt, llm=chat, output_parser=output_parser)\n",
        "\n",
        "recipe = chain.run(dish=\"カレー\")\n",
        "\n",
        "print(type(recipe))\n",
        "print(recipe)"
      ],
      "metadata": {
        "id": "jys6cH41C4NW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SimpleSequentialChain―ChainとChainをつなぐ"
      ],
      "metadata": {
        "id": "iCt-YzvX-z4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "cot_template = \"\"\"以下の質問に回答してください。\n",
        "\n",
        "質問: {question}\n",
        "\n",
        "ステップバイステップで考えましょう。\n",
        "\"\"\"\n",
        "\n",
        "cot_prompt = PromptTemplate(\n",
        "   input_variables=[\"question\"],\n",
        "   template=cot_template,\n",
        ")\n",
        "\n",
        "cot_chain = LLMChain(llm=chat, prompt=cot_prompt)"
      ],
      "metadata": {
        "id": "PcL-GWtO-0v4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize_template = \"\"\"以下の文章を結論だけ一言に要約してください。\n",
        "\n",
        "{input}\n",
        "\"\"\"\n",
        "summarize_prompt = PromptTemplate(\n",
        "   input_variables=[\"input\"],\n",
        "   template=summarize_template,\n",
        ")\n",
        "\n",
        "summarize_chain = LLMChain(llm=chat, prompt=summarize_prompt)"
      ],
      "metadata": {
        "id": "TGTWjr3rKBCX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "\n",
        "cot_summarize_chain = SimpleSequentialChain(chains=[cot_chain, summarize_chain])\n",
        "\n",
        "result = cot_summarize_chain(\n",
        "   \"私は市場に行って10個のリンゴを買いました。隣人に2つ、修理工に2つ渡しました。それから5つのリンゴを買って1つ食べました。残りは何個ですか？\")\n",
        "print(result[\"output\"])"
      ],
      "metadata": {
        "id": "rYGaG5tuKEVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-5 Memory"
      ],
      "metadata": {
        "id": "-jpeYc6ARqBz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ConversationBufferMemory"
      ],
      "metadata": {
        "id": "-yOh1zrMRrbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "import langchain\n",
        "langchain.debug = True\n",
        "langchain.verbose = False\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
        "conversation = ConversationChain(\n",
        "    llm=chat,\n",
        "    memory=ConversationBufferMemory()\n",
        ")\n",
        "\n",
        "while True:\n",
        "    user_message = input(\"You: \")\n",
        "    ai_message = conversation.run(input=user_message)\n",
        "    print(f\"AI: {ai_message}\")"
      ],
      "metadata": {
        "id": "WugAW9-LKGJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
        "    HumanMessage(content=\"こんにちは！私はジョンと言います！\"),\n",
        "    AIMessage(content=\"こんにちは、ジョンさん！どのようにお手伝いできますか？\"),\n",
        "    HumanMessage(content= \"私の名前が分かりますか？\")\n",
        "]\n",
        "\n",
        "result = chat(messages)\n",
        "print(result.content)"
      ],
      "metadata": {
        "id": "zoEzLBS7KLmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-7 Data connection"
      ],
      "metadata": {
        "id": "TrVLB3DPwF8b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Document loaders"
      ],
      "metadata": {
        "id": "Kg6AiTnKwJik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install GitPython"
      ],
      "metadata": {
        "id": "OMbWltTYymkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./langchain"
      ],
      "metadata": {
        "id": "Zfnle0t-qLVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import GitLoader\n",
        "\n",
        "def file_filter(file_path):\n",
        "  return file_path.endswith(\".mdx\")\n",
        "\n",
        "loader = GitLoader(\n",
        "    clone_url=\"https://github.com/langchain-ai/langchain\",\n",
        "    repo_path=\"./langchain\",\n",
        "    branch=\"master\",\n",
        "    file_filter=file_filter,\n",
        ")\n",
        "\n",
        "raw_docs = loader.load()\n",
        "print(len(raw_docs))"
      ],
      "metadata": {
        "id": "uO4jzLUIwK2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Document transformers"
      ],
      "metadata": {
        "id": "ENepdYezyx2K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(raw_docs)\n",
        "print(len(docs))"
      ],
      "metadata": {
        "id": "Z0LDtMDZ56al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text embedding models"
      ],
      "metadata": {
        "id": "ppuF2moQrLYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "PRuScpdhCTSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"AWSのS3からデータを読み込むためのDocumentLoaderはありますか？\"\n",
        "\n",
        "vector = embeddings.embed_query(query)\n",
        "print(len(vector))\n",
        "print(vector)"
      ],
      "metadata": {
        "id": "mDSJOjCLrK_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vector stores"
      ],
      "metadata": {
        "id": "3b23RYe2rQMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet chromadb tiktoken"
      ],
      "metadata": {
        "id": "mWvhGR9BywjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "\n",
        "db = Chroma.from_documents(docs, embeddings)"
      ],
      "metadata": {
        "id": "zgYsSMKnyYRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retriever"
      ],
      "metadata": {
        "id": "u8Uag8bzuDIe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = db.as_retriever()"
      ],
      "metadata": {
        "id": "Rh66m1_luPf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"AWSのS3からデータを読み込むためのDocumentLoaderはありますか？\"\n",
        "\n",
        "context_docs = retriever.get_relevant_documents(query)\n",
        "\n",
        "print(len(context_docs))\n",
        "\n",
        "first_doc = context_docs[0]\n",
        "print(first_doc.metadata)\n",
        "print(first_doc.page_content)"
      ],
      "metadata": {
        "id": "-QB5bVMsyUWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "qa_chain = RetrievalQA.from_chain_type(llm=chat, chain_type=\"stuff\", retriever=retriever)\n",
        "\n",
        "result = qa_chain.run(query)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "d2GNMIC80s2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-8 Agents"
      ],
      "metadata": {
        "id": "E4Fz0OFVZmSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agentsの使用例"
      ],
      "metadata": {
        "id": "8HSybywiZn6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "import langchain\n",
        "langchain.verbose = True\n",
        "langchain.debug = False\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "tools = load_tools([\"terminal\"], llm=chat)\n",
        "agent_chain = initialize_agent(\n",
        "    tools, chat, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
        ")\n",
        "\n",
        "result = agent_chain.run(\"sample_dataディレクトリにあるファイルの一覧を教えて\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "qlRHx6ejZBbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tools"
      ],
      "metadata": {
        "id": "-U2AKd4BsSEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import Tool\n",
        "\n",
        "def my_super_func(input):\n",
        "  return \"42\"\n",
        "\n",
        "tools = [\n",
        "    Tool.from_super_function(\n",
        "        func=my_func,\n",
        "        name=\"The_Answer\",\n",
        "        description=\"生命、宇宙、そして万物についての究極の疑問の答え\"\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "pvJUF7XogVRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "langchain.verbose = True\n",
        "langchain.debug = False\n",
        "\n",
        "agent_chain = initialize_agent(\n",
        "    tools, chat, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
        ")\n",
        "\n",
        "result = agent_chain.run(\"この世界の真理を教えてください\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "MoEjpv2XtemN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain import LLMChain\n",
        "\n",
        "summarize_template = \"\"\"以下の文章を結論だけ一言に要約してください。\n",
        "\n",
        "{input}\n",
        "\"\"\"\n",
        "summarize_prompt = PromptTemplate(\n",
        "   input_variables=[\"input\"],\n",
        "   template=summarize_template,\n",
        ")\n",
        "\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "summarize_chain = LLMChain(llm=chat, prompt=summarize_prompt)\n",
        "\n",
        "tools = [\n",
        "    Tool.from_function(\n",
        "        func=summarize_chain.run,\n",
        "        name=\"Summarizer\",\n",
        "        description=\"Text summarizer\"\n",
        "    ),\n",
        "]\n"
      ],
      "metadata": {
        "id": "MFW6L4Dbtkpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "langchain.verbose = True\n",
        "langchain.debug = False\n",
        "\n",
        "agent_chain = initialize_agent(\n",
        "    tools, chat, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION\n",
        ")\n",
        "\n",
        "input = \"\"\"以下を要約してください。\n",
        "\n",
        "こんにちは！私はChatGPTと呼ばれるAI言語モデルです。OpenAIが開発したGPT-3.5アーキテクチャに基づいています。私は自然言語理解と生成に特化しており、さまざまなトピックに関する質問に答えたり、おしゃべりしたりすることが得意です。\n",
        "\n",
        "私のトレーニングデータは2021年9月までの情報に基づいているため、それ以降の出来事については知識がありません。ですが、できる限りお手伝いすることに努めます。\n",
        "\n",
        "質問や会話、情報の共有など、どんなお手伝いでもお気軽にお申し付けください！よろしくお願いします。\"\"\"\n",
        "\n",
        "result = agent_chain.run(input)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "kAjRYZTLv7nC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents.agent_toolkits import GmailToolkit\n",
        "\n",
        "toolkit = GmailToolkit()\n",
        "tools = toolkit.get_tools()\n",
        "print(tools)"
      ],
      "metadata": {
        "id": "IMhsQCS4wD_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pygithub"
      ],
      "metadata": {
        "id": "7QM4kUUGJof-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.agents.agent_toolkits.github.toolkit import GitHubToolkit\n",
        "from langchain.utilities.github import GitHubAPIWrapper\n",
        "\n",
        "os.environ[\"GITHUB_APP_ID\"] = \"your-github-app-id\"\n",
        "os.environ[\"GITHUB_APP_PRIVATE_KEY\"] = \"/path/to/your/private/key\"\n",
        "os.environ[\"GITHUB_REPOSITORY\"] = \"user/repo\"\n",
        "os.environ[\"GITHUB_BRANCH\"] = \"branch-name\"\n",
        "\n",
        "github = GitHubAPIWrapper()\n",
        "toolkit = GitHubToolkit.from_github_api_wrapper(github)\n",
        "tools = toolkit.get_tools()\n",
        "print(tools)"
      ],
      "metadata": {
        "id": "vbeiMn2t5kcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function callingを使うOpenAI Functions Agent"
      ],
      "metadata": {
        "id": "Q_bTNTRGNZNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "tools = load_tools([\"terminal\"], llm=chat)\n",
        "agent_chain = initialize_agent(tools, chat, agent=AgentType.OPENAI_FUNCTIONS)\n",
        "\n",
        "result = agent_chain.run(\"sample_dataディレクトリにあるファイルの一覧を教えて\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "XP8Nm_1d6zZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 複数のツールを一度に使うOpenAI Multi Functions Agent"
      ],
      "metadata": {
        "id": "BV6Mx0TUO_hT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet duckduckgo-search"
      ],
      "metadata": {
        "id": "bJTSM5gIPDOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "import openai\n",
        "\n",
        "langchain.debug = True\n",
        "langchain.verbose = False\n",
        "openai.log = \"info\""
      ],
      "metadata": {
        "id": "uJAM26YzQQOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "tools = load_tools([\"ddg-search\"])\n",
        "agent_chain = initialize_agent(tools, chat, agent=AgentType.OPENAI_MULTI_FUNCTIONS)\n",
        "\n",
        "result = agent_chain.run(\"東京と大阪の天気を教えてください\")\n",
        "print(result)"
      ],
      "metadata": {
        "id": "EgUyIpfrNq1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.callbacks import HumanApprovalCallbackHandler\n",
        "from langchain.tools import ShellTool\n",
        "\n",
        "tool = ShellTool(callbacks=[HumanApprovalCallbackHandler()])\n",
        "print(tool.run(\"echo Hello World!\"))"
      ],
      "metadata": {
        "id": "vc9JkQUuQXjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### （コラム）Function callingを応用したOurputParser・Extraction・Tagging"
      ],
      "metadata": {
        "id": "IUk1I4cuY_ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import create_extraction_chain, create_extraction_chain_pydantic\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "schema = {\n",
        "    \"properties\": {\n",
        "        \"person_name\": {\"type\": \"string\"},\n",
        "        \"person_height\": {\"type\": \"integer\"},\n",
        "        \"person_hair_color\": {\"type\": \"string\"},\n",
        "        \"dog_name\": {\"type\": \"string\"},\n",
        "        \"dog_breed\": {\"type\": \"string\"},\n",
        "    },\n",
        "    \"required\": [\"person_name\", \"person_height\"],\n",
        "}\n",
        "input = \"\"\"\n",
        "Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\n",
        "Alex's dog Frosty is a labrador and likes to play hide and seek.\n",
        "\"\"\"\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "chain = create_extraction_chain(schema, chat)\n",
        "\n",
        "people = chain.run(input)\n",
        "print(json.dumps(people, indent=2))"
      ],
      "metadata": {
        "id": "G0rOddweWbQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## まとめ"
      ],
      "metadata": {
        "id": "HoyUU671fJ-N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### （コラム）Evaluation"
      ],
      "metadata": {
        "id": "JcGAKOdafMy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.evaluation import load_evaluator\n",
        "\n",
        "chat = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
        "\n",
        "evaluator = load_evaluator(\"qa\", eval_llm=chat)\n",
        "\n",
        "result = evaluator.evaluate_strings(\n",
        "    input=\"私は市場に行って10個のリンゴを買いました。隣人に2つ、修理工に2つ渡しました。それから5つのリンゴを買って1つ食べました。残りは何個ですか？\",\n",
        "    prediction=\"\"\"1最初に10個のリンゴを買い、その中から隣人と修理工にそれぞれ2個ずつ渡しました。そのため、まず手元に残ったリンゴは10 - 2 - 2 = 6個となります。\n",
        "\n",
        "その後、さらに5個のリンゴを買い、1つ食べました。これにより手元のリンゴは6 + 5 - 1 = 10個となります。\"\"\",\n",
        "    reference=\"10個\",\n",
        ")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "KZedGP8fZPtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.evaluation import load_evaluator\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
        "\n",
        "evaluator = load_evaluator(\"qa\", eval_llm=llm)\n",
        "\n",
        "result = evaluator.evaluate_strings(\n",
        "    input=\"パンはパンでも食べられないパンは？\",\n",
        "    prediction=\"フライパン\",\n",
        "    reference=\"フライパン\",\n",
        ")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "BSoBh0vMf753"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EZy6ctSIsWdM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}